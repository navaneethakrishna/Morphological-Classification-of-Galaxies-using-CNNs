{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        self.data = pd.read_csv('training_solutions_rev1/training_solutions_rev1.csv',\\\n",
    "                                nrows =  43136)\n",
    "        self.root_dir = root_dir\n",
    "    def __len__(self):\n",
    "        return len(self.data)  \n",
    "    def __getitem__(self,idx):\n",
    "        img_no = os.path.join(self.root_dir,(str(self.data.iloc[idx, 0]))+'.jpg')\n",
    "        image = io.imread(img_no)\n",
    "        img = image[100:324,100:324]\n",
    "        probs = np.array([self.data.iloc[idx,1:].values]).astype('float')\n",
    "        img = img.transpose((2,0,1))\n",
    "        sample = {'img': img, 'p': probs}\n",
    "        return sample\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        self.data = pd.read_csv('training_solutions_rev1/training_solutions_rev1.csv',\\\n",
    "                                skiprows = 43136, nrows =  12288)\n",
    "        self.root_dir = root_dir\n",
    "    def __len__(self):\n",
    "        return len(self.data)    \n",
    "    def __getitem__(self,idx):\n",
    "        img_no = os.path.join(self.root_dir,(str(self.data.iloc[idx, 0]))+'.jpg')\n",
    "        image = io.imread(img_no)\n",
    "        img = image[100:324,100:324]\n",
    "        probs = np.array([self.data.iloc[idx,1:].values]).astype('float')\n",
    "        img = img.transpose((2,0,1))\n",
    "        sample = {'img': img, 'p': probs}\n",
    "        return sample\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        self.data = pd.read_csv('training_solutions_rev1/training_solutions_rev1.csv',\\\n",
    "                                skiprows = 55424, nrows = 6144)\n",
    "        self.root_dir = root_dir\n",
    "    def __len__(self):\n",
    "        return len(self.data)    \n",
    "    def __getitem__(self,idx):\n",
    "        img_no = os.path.join(self.root_dir,(str(self.data.iloc[idx, 0]))+'.jpg')\n",
    "        image = io.imread(img_no)\n",
    "        img = image[100:324,100:324]\n",
    "        probs = np.array([self.data.iloc[idx,1:].values]).astype('float')\n",
    "        img = img.transpose((2,0,1))\n",
    "        sample = {'img': img, 'p': probs}\n",
    "        return sample\n",
    "\n",
    "transformed_train_dataset = TrainDataset(csv_file = \\\n",
    "                                        'training_solutions_rev1/training_solutions_rev1.csv',\\\n",
    "                                         root_dir = 'images_training_rev1/')\n",
    "transformed_val_dataset = ValDataset(csv_file \\\n",
    "                                     = 'training_solutions_rev1/training_solutions_rev1.csv',\\\n",
    "                                     root_dir = 'images_training_rev1/')\n",
    "transformed_test_dataset = TestDataset(csv_file = \\\n",
    "                                       'training_solutions_rev1/training_solutions_rev1.csv',\\\n",
    "                                       root_dir = 'images_training_rev1/')\n",
    "\n",
    "dataloader_train = DataLoader(transformed_train_dataset,\\\n",
    "                              batch_size = 32, shuffle = False, num_workers = 0)\n",
    "dataloader_val = DataLoader(transformed_val_dataset,\\\n",
    "                            batch_size = 32, shuffle = False, num_workers = 0)\n",
    "dataloader_test = DataLoader(transformed_test_dataset,\\\n",
    "                             batch_size = 32, shuffle = False, num_workers = 0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(str(device))\n",
    "\n",
    "for i,batch in enumerate(dataloader_train):\n",
    "    batch['img'] = batch['img'].to(device)\n",
    "    batch['p'] = batch['p'].to(device)\n",
    "    \n",
    "for j,bat in enumerate(dataloader_val):\n",
    "    bat['img'] = bat['img'].to(device)\n",
    "    bat['p'] = bat['p'].to(device)\n",
    "\n",
    "dataset = {'train' : dataloader_train, 'val' :\\\n",
    "           dataloader_val} # define a composite dataset\n",
    "\n",
    "def train_model(model, criterion,optimizer,scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\n Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        \n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "        \n",
    "            for i,batch in enumerate(dataset[phase]):\n",
    "                inputs = batch['img'].to(device)\n",
    "                labels = batch['p'].to(device)\n",
    "            \n",
    "                optimizer.zero_grad();\n",
    "            \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.type(torch.cuda.FloatTensor))\n",
    "                    loss = criterion(outputs,labels.type(torch.cuda.FloatTensor))\n",
    "                \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                 \n",
    "                running_loss += loss.item()*32\n",
    "        \n",
    "            epoch_loss = running_loss / len(dataset[phase])\n",
    "            if phase == 'val' and epoch == 1:\n",
    "                best_loss = epoch_loss\n",
    "            elif phase == val and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            print('{} Loss: {:.4f}'.format(phase,epoch_loss))\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format\\\n",
    "          (time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Error: {:4f}'.format(best_loss))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "for k,b in enumerate(dataloader_test):\n",
    "    b['img'] = b['img'].to(device)\n",
    "    b['p'] = b['p'].to(device)                                                                                                                                   \n",
    "\n",
    "def test_model(model, criterion):\n",
    "    for i,batch in enumerate(dataloader_test):\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['p'].to(device)\n",
    "    outputs = model(inputs.type(torch.cuda.FloatTensor))\n",
    "    loss = criterion(outputs,labels.type(torch.cuda.FloatTensor))\n",
    "    return loss, outputs,labels\n",
    "\n",
    "model_ft = models.resnet18(pretrained = True)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 500)\n",
    "D_in, H, D_out = 500, 100, 37\n",
    "model = torch.nn.Sequential(\n",
    "    model_ft,\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(H, D_out),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=8)\n",
    "\n",
    "loss, outputs,labels = test_model(model, criterion)\n",
    "print('Test Error = {:4f}'.format(loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
